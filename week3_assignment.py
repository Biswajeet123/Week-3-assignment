# -*- coding: utf-8 -*-
"""Week3 Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eAsn8ghdGsPB0_6Fq01F8gYJ0KuglYfg
"""

import os

os.environ['KAGGLE_USERNAME'] = "XXXXXXXXX"
os.environ['KAGGLE_KEY'] = "XXXXXXXXXXXXXXXXXXXXXXXXXX"

!kaggle competitions download -c ieee-fraud-detection

!unzip train_identity.csv.zip
!unzip train_transaction.csv.zip
!unzip test_identity.csv.zip
!unzip test_transaction.csv.zip

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

train_transaction = pd.read_csv('train_transaction.csv')
test_transaction = pd.read_csv('test_transaction.csv')
train_identity = pd.read_csv('train_identity.csv')
test_identity = pd.read_csv('test_identity.csv')
print('train transaction size:', len(train_transaction))
print('test transaction size:', len(test_transaction))
print('train identity:',len(train_identity))
print('test identity:',len(test_identity))

# let's combine the data and work with the whole dataset
train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')
print("train data size :",train.shape)

len(train[train["isFraud"]==1])/len(train)*100

sns.countplot(x='isFraud', data=train)

plt.figure(figsize=(16,8))
sns.barplot(y=train.isnull().sum().sort_values(ascending=False)/len(train),
            x=train.isnull().sum().sort_values(ascending=False).index,
            palette="Reds_d")
plt.title("Percent Missing Value",size=10)
plt.xticks(rotation=90)

from sklearn.model_selection import train_test_split

columns_def=pd.DataFrame({"na_count":train.isnull().sum().sort_values(ascending=False)})

#Create column of percent columns, #higher is worst
columns_def["per"]=columns_def["na_count"]/len(train)

#cycle throungh various limit for percent Na per column
range=[0.05, 0.10 ,0.15, 0.25, 0.40, 0.60, 0.75]

for i in range: 
    print (columns_def[columns_def["per"]<i].shape[0]/train.shape[1])

limit=0.10 #only columns w/ less 10% will remain

#Select final columns
columns_final=columns_def[columns_def["per"]<limit].index 

train=train[train.columns.intersection(columns_final)]

#Show categorical variables
train[train.select_dtypes(include=['object']).columns]

card6_dummy_df=pd.get_dummies(train["card6"])

train=pd.concat([train,card6_dummy_df],axis=1)

train=train._get_numeric_data()
train=train.dropna()

len(train[train["isFraud"]==1])/len(train)*100

x_full_df=train.drop(["isFraud"],axis=1)
y_full_df=train["isFraud"]

X_train,X_test,y_train,y_test=train_test_split(x_full_df,y_full_df,test_size=0.80)

from sklearn.linear_model import LogisticRegression  
from sklearn.preprocessing import StandardScaler  

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

from sklearn.metrics import recall_score
from sklearn.metrics import accuracy_score

lr = LogisticRegression(solver='lbfgs')  
lr.fit(X_train, y_train)

lr.score(X_test, y_test)

y_pred=lr.predict(X_test)

pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

recall_score(y_test, y_pred)

accuracy_score(y_test, y_pred)